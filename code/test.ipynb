{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "from src.prepare_data import download_data, build_train_vocab, get_train_test_val, check_tokens,tokens_to_sentence , generate_batch , visualize_iter_data , get_embed\n",
    "from src.LSTM import RNNdecoder, RNNencoder,Seq2SeqRNN\n",
    "from src.train import create_mask,generate_square_subsequent_mask, train_epoch, bleu_calculate , evaluate\n",
    "from src.transformer import Seq2SeqTransformer,PositionalEncoding,TokenEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De vocab En vocab:  19215 10838\n",
      "Train Test Val:  29000 1014 1000\n"
     ]
    }
   ],
   "source": [
    "train_filepaths , val_filepaths , test_filepaths = download_data()\n",
    "de_vocab, en_vocab, de_tokenizer, en_tokenizer = build_train_vocab(train_filepaths)\n",
    "print( 'De vocab En vocab: ',len(de_vocab), len(en_vocab))\n",
    "train_data , val_data , test_data = get_train_test_val(train_filepaths, test_filepaths, val_filepaths , de_vocab , en_vocab ,de_tokenizer,en_tokenizer )\n",
    "print('Train Test Val: ',len(train_data),len(test_data) , len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "print(PAD_IDX , BOS_IDX , EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))\n",
    "valid_iter = DataLoader(val_data, batch_size=1,\n",
    "                        shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n",
    "\n",
    "transformer = Seq2SeqTransformer(num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "                                num_decoder_layers= NUM_DECODER_LAYERS,\n",
    "                                emb_size= EMB_SIZE, src_vocab_size= SRC_VOCAB_SIZE,\n",
    "                                 tgt_vocab_size= TGT_VOCAB_SIZE,\n",
    "                                 dim_feedforward= FFN_HID_DIM , NHEAD=NHEAD)\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (src, tgt) in enumerate(train_iter):\n",
    "        #FORWARD\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, pad_idx = PAD_IDX, device=DEVICE)\n",
    "        print('Батч предложений deutch: ',src.shape)\n",
    "        print('Батч переводов english: ',tgt_input.shape)\n",
    "        print('Маска предложений входных: ', src_mask.shape)\n",
    "        print('Маска переводов: ', tgt_mask.shape )\n",
    "        print('Падинг маска предложений входных: ',src_padding_mask.shape)\n",
    "        print('Падинг маска переводов: ',tgt_padding_mask.shape)\n",
    "        logits = transformer.forward(src,\n",
    "                       tgt_input,\n",
    "                       src_mask,\n",
    "                       tgt_mask,\n",
    "                       src_padding_mask,\n",
    "                       tgt_padding_mask,\n",
    "                       src_padding_mask)\n",
    "        print('Предсказания вероятностей слов на каждой позиции: ',logits.shape)\n",
    "\n",
    "        #DECODER\n",
    "\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RNN ENCODER DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_object = get_embed(train_iter = train_iter , EMB_SIZE = EMB_SIZE , DEVICE = DEVICE , SRC_VOCAB_SIZE = SRC_VOCAB_SIZE , PAD_IDX = PAD_IDX )\n",
    "src = data_object['src']\n",
    "tgt = data_object['tgt']\n",
    "src_mask = data_object['src_mask']\n",
    "tgt_mask = data_object['tgt_mask']\n",
    "src_padding_mask = data_object['src_padding_mask']\n",
    "tgt_padding_mask = data_object['tgt_padding_mask']\n",
    "src_emb = data_object['src_emb']\n",
    "tgt_emb = data_object['tgt_emb']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src.permute(1,0)[0]\n",
    "# PositionalEncoding(EMB_SIZE, dropout=0.1)(TokenEmbedding(SRC_VOCAB_SIZE, EMB_SIZE)(src)).permute(1,0,2)[0][:,5]\n",
    "# src_padding_mask[0]\n",
    "# src.permute(1,0)[src_padding_mask].shape\n",
    "# src.permute(1,0)[0][~src_padding_mask[0]]\n",
    "# src_emb.shape , src_mask.shape , src_padding_mask.shape , tgt_emb.shape , tgt_mask.shape , tgt_padding_mask.shape\n",
    "# torch.sum(src_mask , dim=1) ,torch.sum(src_padding_mask , dim=1)  # src_mask из FALSE вся, но src_padding_mask указывает на паддинговые элементы\n",
    "# memory[:,-1:,:] == hidden[0].permute(1,0,2)\n",
    "# tgt_emb.shape , memory.shape , hidden[0].shape , hidden[1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27, 256]) torch.Size([1, 128, 256]) torch.Size([1, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder = RNNencoder(EMB_SIZE,EMB_SIZE )\n",
    "memory, hidden = encoder(src_emb , src_padding_mask)\n",
    "print(memory.shape , hidden[0].shape , hidden[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16,  9, 11, 15, 16, 13, 19, 14, 12, 11, 13, 18, 19, 15, 12, 11, 13, 11,\n",
       "        14, 12, 20, 13, 15, 10, 17, 17, 11, 11, 15, 14, 13, 14, 13, 18, 23, 15,\n",
       "        23, 10, 19,  9, 13, 16, 15, 15, 13, 12, 17, 13, 16, 16, 16, 15, 16, 16,\n",
       "        13, 19, 10, 26, 14, 10, 11, 18, 15, 21, 11, 14, 22, 13, 24, 15, 17, 10,\n",
       "        17, 15, 13, 13, 17, 13, 21, 17, 13, 14, 12, 12, 19, 17, 18, 12, 18, 14,\n",
       "        13, 14, 10, 10, 15, 15, 12, 11, 20, 25, 16, 14, 12, 24, 10, 16, 18, 18,\n",
       "        14, 14, 26, 23, 12, 16, 15, 12, 19, 13,  8, 13, 23, 16, 20, 19, 12, 14,\n",
       "        13, 11], dtype=torch.int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = (~tgt_padding_mask).sum(1).int()\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 128, 256])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = tgt_emb \n",
    "result = []\n",
    "lstm = torch.nn.LSTM(EMB_SIZE, EMB_SIZE, batch_first=True)\n",
    "\n",
    "result,_ = lstm(input.permute(1,0,2))\n",
    "\n",
    "# for i in range(input.shape[0]) :\n",
    "#     print(act.shape)\n",
    "#     act = input[i:i+1,:,:]\n",
    "#     act = act.permute(1,0,2)\n",
    "#     act, hidden = lstm(act,  (hidden[0] , hidden[1]))\n",
    "#     result.append(act)\n",
    "\n",
    "# result = torch.stack(result).squeeze(2)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26, 256])\n"
     ]
    }
   ],
   "source": [
    "decoder = RNNdecoder(EMB_SIZE , EMB_SIZE )\n",
    "decode_output  = decoder(tgt_emb , memory , hidden ,tgt_padding_mask )\n",
    "print(decode_output.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#seq2sew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "rnn = Seq2SeqRNN(emb_size= EMB_SIZE, \n",
    "                src_vocab_size= SRC_VOCAB_SIZE,\n",
    "                tgt_vocab_size= TGT_VOCAB_SIZE,\n",
    "                hidden_size= FFN_HID_DIM)\n",
    "for p in rnn.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "rnn = rnn.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    rnn.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26, 10838])\n"
     ]
    }
   ],
   "source": [
    "out_forward = rnn.forward(src,tgt, src_padding_mask, tgt_padding_mask)\n",
    "print(out_forward.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    print('train')\n",
    "    train_loss = train_epoch(rnn, train_iter, optimizer , DEVICE =DEVICE , loss_fn =loss_fn , pad_idx = PAD_IDX)\n",
    "    end_time = time.time()\n",
    "    print('eval')\n",
    "    val_loss = evaluate(rnn, valid_iter , DEVICE =DEVICE , loss_fn =loss_fn,  pad_idx = PAD_IDX)\n",
    "    print('bleu')\n",
    "    bleu = bleu_calculate(rnn, valid_iter, en_vocab = en_vocab ,de_vocab = de_vocab ,de_tokenizer = de_tokenizer ,DEVICE = DEVICE , EOS_IDX = EOS_IDX ,BOS_IDX = BOS_IDX)\n",
    "    all_time = time.time()\n",
    "    print(f\"Epoch: {epoch}, \"\n",
    "          f\"Train loss: {train_loss:.3f}, \"\n",
    "          f\"Val loss: {val_loss:.3f}, \"\n",
    "          f\"Blue: {bleu:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
    "          f\"All time = {(all_time - start_time):.3f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
