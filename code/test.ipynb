{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "from src.prepare_data import download_data, build_train_vocab, get_train_test_val, check_tokens,tokens_to_sentence , generate_batch , visualize_iter_data , get_embed\n",
    "from src.LSTM import RNNdecoder, RNNencoder,Seq2SeqRNN\n",
    "from src.train import create_mask,generate_square_subsequent_mask, train_epoch, bleu_calculate , evaluate\n",
    "from src.transformer import Seq2SeqTransformer,PositionalEncoding,TokenEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !python3 -m spacy info # spacy работает на версиях питона от 3.10\n",
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De vocab En vocab:  19215 10838\n",
      "Train Test Val:  29000 1014 1000\n"
     ]
    }
   ],
   "source": [
    "train_filepaths , val_filepaths , test_filepaths = download_data()\n",
    "de_vocab, en_vocab, de_tokenizer, en_tokenizer = build_train_vocab(train_filepaths)\n",
    "print( 'De vocab En vocab: ',len(de_vocab), len(en_vocab))\n",
    "train_data , val_data , test_data = get_train_test_val(train_filepaths, test_filepaths, val_filepaths , de_vocab , en_vocab ,de_tokenizer,en_tokenizer )\n",
    "print('Train Test Val: ',len(train_data),len(test_data) , len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "print(PAD_IDX , BOS_IDX , EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))\n",
    "valid_iter = DataLoader(val_data, batch_size=1,\n",
    "                        shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoreshka/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n",
    "\n",
    "transformer = Seq2SeqTransformer(num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "                                num_decoder_layers= NUM_DECODER_LAYERS,\n",
    "                                emb_size= EMB_SIZE, src_vocab_size= SRC_VOCAB_SIZE,\n",
    "                                 tgt_vocab_size= TGT_VOCAB_SIZE,\n",
    "                                 dim_feedforward= FFN_HID_DIM , NHEAD=NHEAD)\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 1, Train loss: 0.279, Val loss: 0.061, Blue: 0.000, Epoch time = 19.858s, All time = 21.949s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 2, Train loss: 0.268, Val loss: 0.060, Blue: 0.000, Epoch time = 32.781s, All time = 34.947s\n",
      "train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[188], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train_loss \u001b[39m=\u001b[39m train_epoch(transformer, train_iter, optimizer , DEVICE \u001b[39m=\u001b[39;49mDEVICE , loss_fn \u001b[39m=\u001b[39;49mloss_fn , pad_idx \u001b[39m=\u001b[39;49m PAD_IDX)\n\u001b[1;32m      5\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/DIPLOM/Ignashin-BS-Thesis/code/src/train.py:330\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_iter, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m tgt_out \u001b[39m=\u001b[39m tgt[\u001b[39m1\u001b[39m:, :]\n\u001b[1;32m    329\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, logits\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), tgt_out\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 330\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    331\u001b[0m \u001b[39m# print('1')\u001b[39;00m\n\u001b[1;32m    332\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    print('train')\n",
    "    train_loss = train_epoch(transformer, train_iter, optimizer , DEVICE =DEVICE , loss_fn =loss_fn , pad_idx = PAD_IDX)\n",
    "    end_time = time.time()\n",
    "    print('eval')\n",
    "    val_loss = evaluate(transformer, valid_iter , DEVICE =DEVICE , loss_fn =loss_fn,  pad_idx = PAD_IDX)\n",
    "    print('bleu')\n",
    "    bleu = bleu_calculate(transformer, valid_iter, en_vocab = en_vocab ,de_vocab = de_vocab ,de_tokenizer = de_tokenizer ,DEVICE = DEVICE , EOS_IDX = EOS_IDX ,BOS_IDX = BOS_IDX, transformer=True)\n",
    "    all_time = time.time()\n",
    "    print(f\"Epoch: {epoch}, \"\n",
    "          f\"Train loss: {train_loss:.3f}, \"\n",
    "          f\"Val loss: {val_loss:.3f}, \"\n",
    "          f\"Blue: {bleu:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
    "          f\"All time = {(all_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (src, tgt) in enumerate(train_iter):\n",
    "        #FORWARD\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, pad_idx = PAD_IDX, device=DEVICE)\n",
    "        print('Батч предложений deutch: ',src.shape)\n",
    "        print('Батч переводов english: ',tgt_input.shape)\n",
    "        print('Маска предложений входных: ', src_mask.shape)\n",
    "        print('Маска переводов: ', tgt_mask.shape )\n",
    "        print('Падинг маска предложений входных: ',src_padding_mask.shape)\n",
    "        print('Падинг маска переводов: ',tgt_padding_mask.shape)\n",
    "        logits = transformer.forward(src,\n",
    "                       tgt_input,\n",
    "                       src_mask,\n",
    "                       tgt_mask,\n",
    "                       src_padding_mask,\n",
    "                       tgt_padding_mask,\n",
    "                       src_padding_mask)\n",
    "        print('Предсказания вероятностей слов на каждой позиции: ',logits.shape)\n",
    "\n",
    "        #DECODER\n",
    "\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RNN ENCODER DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_object = get_embed(train_iter = train_iter , EMB_SIZE = EMB_SIZE , DEVICE = DEVICE , SRC_VOCAB_SIZE = SRC_VOCAB_SIZE , PAD_IDX = PAD_IDX )\n",
    "src = data_object['src']\n",
    "tgt = data_object['tgt']\n",
    "src_mask = data_object['src_mask']\n",
    "tgt_mask = data_object['tgt_mask']\n",
    "src_padding_mask = data_object['src_padding_mask']\n",
    "tgt_padding_mask = data_object['tgt_padding_mask']\n",
    "src_emb = data_object['src_emb']\n",
    "tgt_emb = data_object['tgt_emb']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 128, 256]),\n",
       " torch.Size([27, 27]),\n",
       " torch.Size([128, 27]),\n",
       " torch.Size([26, 128, 256]),\n",
       " torch.Size([26, 26]),\n",
       " torch.Size([128, 26]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src.permute(1,0)[0]\n",
    "# PositionalEncoding(EMB_SIZE, dropout=0.1)(TokenEmbedding(SRC_VOCAB_SIZE, EMB_SIZE)(src)).permute(1,0,2)[0][:,5]\n",
    "# src_padding_mask[0]\n",
    "# src.permute(1,0)[src_padding_mask].shape\n",
    "# src.permute(1,0)[0][~src_padding_mask[0]]\n",
    "src_emb.shape , src_mask.shape , src_padding_mask.shape , tgt_emb.shape , tgt_mask.shape , tgt_padding_mask.shape\n",
    "# torch.sum(src_mask , dim=1) ,torch.sum(src_padding_mask , dim=1)  # src_mask из FALSE вся, но src_padding_mask указывает на паддинговые элементы\n",
    "# memory[:,-1:,:] == hidden[0].permute(1,0,2)\n",
    "# tgt_emb.shape , memory.shape , hidden[0].shape , hidden[1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 17, 16, 13, 13, 11,  9,  8, 13, 17, 16, 12,  7, 11, 18, 18, 11, 15,\n",
       "        13, 15,  6, 15, 13, 17, 12, 10, 16, 14, 12,  9, 13, 17, 16, 15,  7, 15,\n",
       "         7, 16,  5, 14, 14, 12, 16, 13, 13, 17, 12, 14, 11, 12, 11, 12,  9, 13,\n",
       "        19, 10, 17,  8, 16, 17, 17, 11, 13,  6, 14, 13,  5, 14,  7, 14, 12, 17,\n",
       "        10, 10, 11, 16, 10, 11,  7, 10, 17, 13, 15, 16, 12, 13, 11, 16,  7, 12,\n",
       "        16, 14, 17, 18, 15, 12, 15, 18,  9,  3, 13, 16, 15,  7, 17, 13,  9, 13,\n",
       "        16, 16,  0,  4, 15, 14, 17, 14,  9, 13, 21, 16,  6,  8, 13, 10, 12, 12,\n",
       "        14, 16])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(src_padding_mask, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27, 256]) torch.Size([1, 128, 256]) torch.Size([1, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder = RNNencoder(EMB_SIZE,EMB_SIZE )\n",
    "memory, hidden = encoder(src_emb , src_padding_mask)\n",
    "print(memory.shape , hidden[0].shape , hidden[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16,  9, 11, 15, 16, 13, 19, 14, 12, 11, 13, 18, 19, 15, 12, 11, 13, 11,\n",
       "        14, 12, 20, 13, 15, 10, 17, 17, 11, 11, 15, 14, 13, 14, 13, 18, 23, 15,\n",
       "        23, 10, 19,  9, 13, 16, 15, 15, 13, 12, 17, 13, 16, 16, 16, 15, 16, 16,\n",
       "        13, 19, 10, 26, 14, 10, 11, 18, 15, 21, 11, 14, 22, 13, 24, 15, 17, 10,\n",
       "        17, 15, 13, 13, 17, 13, 21, 17, 13, 14, 12, 12, 19, 17, 18, 12, 18, 14,\n",
       "        13, 14, 10, 10, 15, 15, 12, 11, 20, 25, 16, 14, 12, 24, 10, 16, 18, 18,\n",
       "        14, 14, 26, 23, 12, 16, 15, 12, 19, 13,  8, 13, 23, 16, 20, 19, 12, 14,\n",
       "        13, 11], dtype=torch.int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = (~tgt_padding_mask).sum(1).int()\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 128, 256])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = tgt_emb \n",
    "result = []\n",
    "lstm = torch.nn.LSTM(EMB_SIZE, EMB_SIZE, batch_first=True)\n",
    "\n",
    "result,_ = lstm(input.permute(1,0,2))\n",
    "\n",
    "# for i in range(input.shape[0]) :\n",
    "#     print(act.shape)\n",
    "#     act = input[i:i+1,:,:]\n",
    "#     act = act.permute(1,0,2)\n",
    "#     act, hidden = lstm(act,  (hidden[0] , hidden[1]))\n",
    "#     result.append(act)\n",
    "\n",
    "# result = torch.stack(result).squeeze(2)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26, 256])\n"
     ]
    }
   ],
   "source": [
    "decoder = RNNdecoder(EMB_SIZE , EMB_SIZE )\n",
    "decode_output  = decoder.forward(input = tgt_emb , memory= memory ,hidden=hidden , tgt_padding_mask = tgt_padding_mask )\n",
    "print(decode_output.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 64\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 64\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "rnn = Seq2SeqRNN(emb_size= EMB_SIZE, \n",
    "                src_vocab_size= SRC_VOCAB_SIZE,\n",
    "                tgt_vocab_size= TGT_VOCAB_SIZE,\n",
    "                hidden_size= FFN_HID_DIM)\n",
    "for p in rnn.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "rnn = rnn.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    rnn.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26, 10838])\n"
     ]
    }
   ],
   "source": [
    "out_forward = rnn.forward(src,tgt, src_mask , tgt_mask , src_padding_mask, tgt_padding_mask , src_padding_mask)\n",
    "print(out_forward.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 1, Train loss: 0.285, Val loss: 0.064, Blue: 0.002, Epoch time = 8.194s, All time = 8.626s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 2, Train loss: 0.285, Val loss: 0.064, Blue: 0.004, Epoch time = 6.972s, All time = 7.413s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 3, Train loss: 0.284, Val loss: 0.064, Blue: 0.004, Epoch time = 8.292s, All time = 8.999s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 4, Train loss: 0.283, Val loss: 0.063, Blue: 0.005, Epoch time = 8.259s, All time = 8.748s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 5, Train loss: 0.282, Val loss: 0.063, Blue: 0.005, Epoch time = 8.095s, All time = 8.557s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 6, Train loss: 0.282, Val loss: 0.063, Blue: 0.005, Epoch time = 8.817s, All time = 9.288s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 7, Train loss: 0.281, Val loss: 0.062, Blue: 0.006, Epoch time = 8.551s, All time = 9.033s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 8, Train loss: 0.280, Val loss: 0.062, Blue: 0.007, Epoch time = 7.903s, All time = 8.380s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 9, Train loss: 0.278, Val loss: 0.061, Blue: 0.004, Epoch time = 7.816s, All time = 8.279s\n",
      "train\n",
      "eval\n",
      "bleu\n",
      "Epoch: 10, Train loss: 0.276, Val loss: 0.061, Blue: 0.005, Epoch time = 7.718s, All time = 8.131s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    print('train')\n",
    "    train_loss = train_epoch(rnn, train_iter, optimizer , DEVICE =DEVICE , loss_fn =loss_fn , pad_idx = PAD_IDX)\n",
    "    end_time = time.time()\n",
    "    print('eval')\n",
    "    val_loss = evaluate(rnn, valid_iter , DEVICE =DEVICE , loss_fn =loss_fn,  pad_idx = PAD_IDX)\n",
    "    print('bleu')\n",
    "    bleu = bleu_calculate(rnn, valid_iter, en_vocab = en_vocab ,de_vocab = de_vocab ,de_tokenizer = de_tokenizer ,DEVICE = DEVICE , EOS_IDX = EOS_IDX ,BOS_IDX = BOS_IDX, transformer=False)\n",
    "    all_time = time.time()\n",
    "    print(f\"Epoch: {epoch}, \"\n",
    "          f\"Train loss: {train_loss:.3f}, \"\n",
    "          f\"Val loss: {val_loss:.3f}, \"\n",
    "          f\"Blue: {bleu:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
    "          f\"All time = {(all_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
