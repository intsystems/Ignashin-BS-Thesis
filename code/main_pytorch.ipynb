{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd code    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'vocab' from 'torchtext.vocab' (/home/igoreshka/miniconda3/lib/python3.10/site-packages/torchtext/vocab.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m (TransformerEncoder, TransformerDecoder,\n\u001b[1;32m     14\u001b[0m                       TransformerEncoderLayer, TransformerDecoderLayer)\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprepare_data\u001b[39;00m \u001b[39mimport\u001b[39;00m download_data, build_train_vocab, get_train_test_val, check_tokens,tokens_to_sentence , generate_batch , visualize_iter_data , get_embed\n\u001b[1;32m     17\u001b[0m \u001b[39m# from src.LSTM import RNNdecoder, RNNencoder,Seq2SeqRNN\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m create_mask,generate_square_subsequent_mask, train_epoch, bleu_calculate , evaluate\n",
      "File \u001b[0;32m~/Desktop/DIPLOM/Ignashin-BS-Thesis/code/src/prepare_data.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvocab\u001b[39;00m \u001b[39mimport\u001b[39;00m vocab\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tokenizer\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrnn\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequence\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'vocab' from 'torchtext.vocab' (/home/igoreshka/miniconda3/lib/python3.10/site-packages/torchtext/vocab.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "from src.prepare_data import download_data, build_train_vocab, get_train_test_val, check_tokens,tokens_to_sentence , generate_batch , visualize_iter_data , get_embed\n",
    "# from src.LSTM import RNNdecoder, RNNencoder,Seq2SeqRNN\n",
    "from src.train import create_mask,generate_square_subsequent_mask, train_epoch, bleu_calculate , evaluate\n",
    "# from src.transformer import Seq2SeqTransformer,PositionalEncoding,TokenEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,9,9,9,9,9,3,2,2,2,2,2]]).unsqueeze(-1)\n",
    "b = torch.Tensor([[1,9,9,9,9,9,9,9,3,2,2,2]]).unsqueeze(-1)\n",
    "c = torch.Tensor([[1,9,9,9,9,9,9,9,9,9,9,3]]).unsqueeze(-1)\n",
    "d = torch.Tensor([[1,9,9,9,9,9,9,9,9,9,3,2]]).unsqueeze(-1)\n",
    "A = torch.cat([a,b,c,d])\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (A != 2)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_A = A*mask\n",
    "new_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0833],\n",
       "        [5.5833],\n",
       "        [7.8333],\n",
       "        [7.0833]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = new_A.mean(1) \n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.LSTM_pytorch as srcLSTM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De vocab En vocab:  19215 10838\n",
      "Train Test Val:  29000 1014 1000\n"
     ]
    }
   ],
   "source": [
    "train_filepaths , val_filepaths , test_filepaths = download_data()\n",
    "de_vocab, en_vocab, de_tokenizer, en_tokenizer = build_train_vocab(train_filepaths)\n",
    "print( 'De vocab En vocab: ',len(de_vocab), len(en_vocab))\n",
    "train_data , val_data , test_data = get_train_test_val(train_filepaths, test_filepaths, val_filepaths , de_vocab , en_vocab ,de_tokenizer,en_tokenizer )\n",
    "print('Train Test Val: ',len(train_data),len(test_data) , len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "print(PAD_IDX , BOS_IDX , EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepareData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m hidden_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[0;32m----> 4\u001b[0m input_lang, output_lang, train_dataloader \u001b[39m=\u001b[39m srcLSTM\u001b[39m.\u001b[39;49mget_dataloader(batch_size)\n\u001b[1;32m      6\u001b[0m encoder \u001b[39m=\u001b[39m srcLSTM\u001b[39m.\u001b[39mEncoderRNN(input_lang\u001b[39m.\u001b[39mn_words, hidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m decoder \u001b[39m=\u001b[39m srcLSTM\u001b[39m.\u001b[39mAttnDecoderRNN(hidden_size, output_lang\u001b[39m.\u001b[39mn_words)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/DIPLOM/Ignashin-BS-Thesis/code/src/LSTM_pytorch.py:141\u001b[0m, in \u001b[0;36mget_dataloader\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataloader\u001b[39m(batch_size):\n\u001b[0;32m--> 141\u001b[0m     input_lang, output_lang, pairs \u001b[39m=\u001b[39m prepareData(\u001b[39m'\u001b[39m\u001b[39meng\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfra\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    143\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(pairs)\n\u001b[1;32m    144\u001b[0m     input_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n, MAX_LENGTH), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepareData' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = srcLSTM.get_dataloader(batch_size)\n",
    "\n",
    "encoder = srcLSTM.EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = srcLSTM.AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "srcLSTM.train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
