{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "2meJOjwRzbjs"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
        "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
        "\n",
        "from src.prepare_data import download_data, build_train_vocab, get_train_test_val, check_tokens,tokens_to_sentence , generate_batch , visualize_iter_data , get_embed\n",
        "# from src.LSTM import \n",
        "from src.train import create_mask,generate_square_subsequent_mask, train_epoch , evaluate, bleu_calculate\n",
        "from src.transformer import Seq2SeqTransformer,PositionalEncoding,TokenEmbedding\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "cf0vks2CAiN_"
      },
      "outputs": [],
      "source": [
        "# !pip freeze > requirements.txt\n",
        "# !python3 -m spacy info # spacy работает на версиях питона от 3.10\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "De vocab En vocab:  19215 10838\n",
            "Train Test Val:  29000 1014 1000\n"
          ]
        }
      ],
      "source": [
        "train_filepaths , val_filepaths , test_filepaths = download_data()\n",
        "de_vocab, en_vocab, de_tokenizer, en_tokenizer = build_train_vocab(train_filepaths)\n",
        "print( 'De vocab En vocab: ',len(de_vocab), len(en_vocab))\n",
        "train_data , val_data , test_data = get_train_test_val(train_filepaths, test_filepaths, val_filepaths , de_vocab , en_vocab ,de_tokenizer,en_tokenizer )\n",
        "print('Train Test Val: ',len(train_data),len(test_data) , len(val_data))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PF-hjEIvO1LR"
      },
      "source": [
        "#### Special symbols\n",
        "EXAMPLE: [BOS_IDX , token1 , token2 , token3 , EOS_IDX , PAD_IX , PAD_IX , PAD_IX]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRGdLX387BH5",
        "outputId": "d22ddba6-f819-447b-d5fc-bff9e32463cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 2 3\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "PAD_IDX = de_vocab['<pad>']\n",
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']\n",
        "print(PAD_IDX , BOS_IDX , EOS_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_fIbCczW9Js_"
      },
      "outputs": [],
      "source": [
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))\n",
        "valid_iter = DataLoader(val_data, batch_size=1,\n",
        "                        shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))\n",
        "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "                       shuffle=True, collate_fn= lambda x : generate_batch(x , BOS_IDX=BOS_IDX,PAD_IDX=PAD_IDX,EOS_IDX=EOS_IDX))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4VjE6hLmUrKK"
      },
      "source": [
        "# SEQ2SEQ train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "oNvgerfS9poj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/igoreshka/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "SRC_VOCAB_SIZE = len(de_vocab)\n",
        "TGT_VOCAB_SIZE = len(en_vocab)\n",
        "EMB_SIZE = 32\n",
        "NHEAD = 2\n",
        "FFN_HID_DIM = 32\n",
        "BATCH_SIZE = 32\n",
        "NUM_ENCODER_LAYERS = 2\n",
        "NUM_DECODER_LAYERS = 2\n",
        "NUM_EPOCHS = 8\n",
        "\n",
        "\n",
        "transformer = Seq2SeqTransformer(num_encoder_layers=NUM_ENCODER_LAYERS,\n",
        "                                num_decoder_layers= NUM_DECODER_LAYERS,\n",
        "                                emb_size= EMB_SIZE, src_vocab_size= SRC_VOCAB_SIZE,\n",
        "                                 tgt_vocab_size= TGT_VOCAB_SIZE,\n",
        "                                 dim_feedforward= FFN_HID_DIM , NHEAD=NHEAD)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxpm6sSM9v8s"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = time.time()\n",
        "    print('train')\n",
        "    train_loss = train_epoch(transformer, train_iter, optimizer , DEVICE =DEVICE , loss_fn =loss_fn , pad_idx = PAD_IDX)\n",
        "    end_time = time.time()\n",
        "    print('eval')\n",
        "    val_loss = evaluate(transformer, valid_iter , DEVICE =DEVICE , loss_fn =loss_fn,  pad_idx = PAD_IDX)\n",
        "    print('bleu')\n",
        "    bleu = bleu_calculate(transformer, valid_iter, en_vocab = en_vocab ,de_vocab = de_vocab ,de_tokenizer = de_tokenizer ,DEVICE = DEVICE , EOS_IDX = EOS_IDX ,BOS_IDX = BOS_IDX)\n",
        "    all_time = time.time()\n",
        "    print(f\"Epoch: {epoch}, \"\n",
        "          f\"Train loss: {train_loss:.3f}, \"\n",
        "          f\"Val loss: {val_loss:.3f}, \"\n",
        "          f\"Blue: {bleu:.3f}, \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
        "          f\"All time = {(all_time - start_time):.3f}s\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VzUUJx80095Q"
      },
      "source": [
        "# RNN encoder-decoder train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "swWZxnKj1vlj"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = len(de_vocab)\n",
        "TGT_VOCAB_SIZE = len(en_vocab)\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "NUM_EPOCHS = 16\n",
        "\n",
        "\n",
        "rnn = Seq2SeqRNN(NUM_ENCODER_LAYERS,\n",
        "                                 NUM_DECODER_LAYERS,\n",
        "                                 EMB_SIZE, SRC_VOCAB_SIZE,\n",
        "                                 TGT_VOCAB_SIZE,\n",
        "                                 FFN_HID_DIM)\n",
        "\n",
        "for p in rnn.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "HGOIt3WsNB1x"
      },
      "outputs": [],
      "source": [
        "out_forward = rnn.forward(src,tgt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIKlqg66NR8T",
        "outputId": "1f041ad8-6b33-42f8-f43a-5e45b4ebb35b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([26, 128, 10838])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_forward.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "x-rXtrI-N0Sm"
      },
      "outputs": [],
      "source": [
        "out_encode = rnn.encode(src)\n",
        "out_decode = rnn.decode(tgt , out_encode[0] , out_encode[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACkaMhcSOlxL",
        "outputId": "93af7b8a-8aa8-4344-bec8-ef3709c08b52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([26, 128, 512])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_decode.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YjZxOZ3EfvG"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = time.time()\n",
        "    train_loss = train_epoch(transformer, train_iter, optimizer)\n",
        "    end_time = time.time()\n",
        "    val_loss = evaluate(transformer, valid_iter)\n",
        "    bleu = bleu_calculate(transformer, valid_iter)\n",
        "    all_time = time.time()\n",
        "    print(f\"Epoch: {epoch}, \"\n",
        "          f\"Train loss: {train_loss:.3f}, \"\n",
        "          f\"Val loss: {val_loss:.3f}, \"\n",
        "          f\"Blue: {bleu:.3f}, \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s, \"\n",
        "          f\"All time = {(all_time - start_time):.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v3b0HTGIRjn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stCe_6jKIRde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMVq8z-ZIRVr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxsy-NEVIOmp"
      },
      "source": [
        "# Добавляем ATTENTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgkDahbmnTWf"
      },
      "outputs": [],
      "source": [
        "class Attention(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
        "        super().__init__()\n",
        "        self.encoder_dim = encoder_dim\n",
        "        self.decoder_dim = decoder_dim\n",
        "\n",
        "    def forward(self,\n",
        "        query: torch.Tensor,  # [decoder_dim]\n",
        "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
        "        ):\n",
        "        weights = self._get_weights(query, values) # [seq_length]\n",
        "        weights = torch.nn.functional.softmax(weights, dim=0)\n",
        "        return weights @ values  # [encoder_dim]\n",
        "\n",
        "class AdditiveAttention(Attention):\n",
        "\n",
        "    def __init__(self, encoder_dim, decoder_dim):\n",
        "        super().__init__(encoder_dim, decoder_dim)\n",
        "        self.v = torch.nn.Parameter(\n",
        "            torch.FloatTensor(self.decoder_dim).uniform_(-0.1, 0.1))\n",
        "        self.W_1 = torch.nn.Linear(self.decoder_dim, self.decoder_dim)\n",
        "        self.W_2 = torch.nn.Linear(self.encoder_dim, self.decoder_dim)\n",
        "\n",
        "    def _get_weights(self,\n",
        "        query: torch.Tensor,  # [decoder_dim]\n",
        "        values: torch.Tensor,  # [seq_length, encoder_dim]\n",
        "    ):\n",
        "        query = query.repeat(values.size(0), 1)  # [seq_length, decoder_dim]\n",
        "        weights = self.W_1(query) + self.W_2(values)  # [seq_length, decoder_dim]\n",
        "        return torch.tanh(weights) @ self.v  # [seq_length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKZZc0KWtZfW",
        "outputId": "b64a400a-a33d-4823-8089-57428da26c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 20])\n"
          ]
        }
      ],
      "source": [
        "attention = Attention( query_size = 20, key_size = 10 )\n",
        "hidden = torch.randn(1, 1, 10)\n",
        "embs = torch.randn(1, 5, 20)\n",
        "\n",
        "context = attention(hidden=hidden , embs=embs)\n",
        "print(context.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuU0lSMPiIF9"
      },
      "outputs": [],
      "source": [
        "MAX_GENERATE = 20\n",
        "class RNN_Att(nn.Module) :\n",
        "    def __init__(self , input_size , encoder_size ,decoder_size , output_size ) :\n",
        "        super(RNN_Att, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_encoder_size = encoder_size\n",
        "        self.hidden_decoder_size = decoder_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder = RNNEncoder(input_size = self.input_size, hidden_size = self.hidden_encoder_size)\n",
        "        # print(self.query_size , self.hidden_decoder_size )\n",
        "\n",
        "        self.attention = Attention(query_size = self.hidden_encoder_size , key_size = self.hidden_decoder_size)\n",
        "        self.decoder = RNNDecoder(self.hidden_encoder_size, self.hidden_decoder_size, self.output_size)\n",
        "\n",
        "    def forward(self , input_sequence ) :\n",
        "        initial_hidden = torch.zeros(1,1,self.hidden_encoder_size)\n",
        "        # print(input_sequence.shape, initial_hidden.shape )\n",
        "        encoder_hidden, _ = self.encoder(input_sequence, initial_hidden) # hidden layers of encoder\n",
        "        # print(encoder_hidden.shape)\n",
        "        #INITALIZATION\n",
        "        initial_output = torch.zeros(1,1,self.output_size)\n",
        "        decoder_hidden = torch.zeros(1,1,self.hidden_decoder_size)\n",
        "        current_output = initial_output\n",
        "\n",
        "        #GENERATE current_output\n",
        "        output_sequence = []\n",
        "        for j in range(MAX_GENERATE) :\n",
        "            context = self.attention(hidden=decoder_hidden , embs=encoder_hidden)\n",
        "            decoder_hidden , current_output = self.decoder(context , decoder_hidden , current_output )\n",
        "            output_sequence.append(current_output)\n",
        "            # Условие, что сгенерировался конечный токен\n",
        "            # if current_output\n",
        "            #     break\n",
        "\n",
        "        output_sequence = torch.cat(output_sequence, dim=1)\n",
        "        # print(output_sequence.shape)\n",
        "        # output_sequence = output_sequence.permute(1,0,3,2)\n",
        "        # output_sequence = output_sequence.squeeze(3)\n",
        "        return output_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmmuqkcDkj8G"
      },
      "outputs": [],
      "source": [
        "input_size = 30 ; encoder_size = 15 ;decoder_size = 20 ; output_size = 30\n",
        "rnn_att = RNN_Att( input_size = input_size, encoder_size = encoder_size ,decoder_size=decoder_size , output_size=output_size)\n",
        "input_sequence = torch.randn(1, 5, input_size)\n",
        "\n",
        "ouput_sequence = rnn_att(input_sequence)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQsLZh2br5JB",
        "outputId": "09fa3a23-3c46-48c2-bf93-8255b45c61fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 5, 15, 1])\n",
            "torch.Size([4, 5, 15])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(5,4,1,15)\n",
        "b = a.permute(1,0,3,2)\n",
        "print(b.shape)\n",
        "c = b.squeeze(3)\n",
        "print(c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0v-NSQqsDmp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
